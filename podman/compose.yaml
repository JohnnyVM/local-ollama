version: "3.8"  
services:  
  ollama:  
    image: docker.io/ollama/ollama:latest  
    container_name: ollama  
    restart: unless-stopped  
    ports:  
      - "11434:11434"  
    environment:  
      OLLAMA_HOST: 0.0.0.0  
      MODEL_LIST_FILE: /models/preload.txt  
      OLLAMA_HOME: /root/.ollama  
      NVIDIA_VISIBLE_DEVICES: all  
    volumes:  
      - ./data:/root/.ollama:Z  
      - ./entrypoint.sh:/entrypoint.sh:Z  
      - ./models.txt:/models/preload.txt:ro,Z  
    entrypoint:  
      - /bin/sh  
      - /entrypoint.sh  
    deploy:  
      resources:  
        reservations:  
          devices:  
            - driver: nvidia  
              count: all  
              capabilities: [gpu]  
    # If using older Docker you may need:  
    healthcheck:  
      test:  
        - CMD  
        - /bin/sh  
        - -c  
        - curl -fsS http://127.0.0.1:11434/api/version >/dev/null  
      interval: 30s  
      timeout: 10s  
      retries: 5  
      start_period: 30s  
